import os
import uuid
import gradio as gr
import yaml
import imageio
import numpy as np
import torch

from skimage.transform import resize
from skimage import img_as_ubyte

# ç›´æ¥å¤ç”¨ä»“åº“é‡Œçš„å‡½æ•°ï¼ˆä¸å†èµ·å­è¿›ç¨‹ï¼‰
from demo import load_checkpoints, make_animation


# ---------------------------
# 1) æ¨¡å‹é…ç½®
# ---------------------------
MODEL_CONFIG = {
    "äººè„¸æ¨¡å‹ (vox)": {
        "config_path": "config/vox-256.yaml",
        "checkpoint_path": "checkpoints/vox-cpk.pth.tar"
    },
    "äººè„¸æ¨¡å‹-é«˜æ¸… (vox-adv)": {
        "config_path": "config/vox-adv-256.yaml",
        "checkpoint_path": "checkpoints/vox-adv-cpk.pth.tar"
    },
    "å…¨èº«åŠ¨ä½œ (taichi)": {
        "config_path": "config/taichi-256.yaml",
        "checkpoint_path": "checkpoints/taichi-cpk.pth.tar"
    },
    "æ—¶å°šæ¨¡å‹ (fashion)": {
        "config_path": "config/fashion-256.yaml",
        "checkpoint_path": "checkpoints/fashion-cpk.pth.tar"
    },
    "åŠ¨ç”»æ¨¡å‹ (mgif)": {
        "config_path": "config/mgif-256.yaml",
        "checkpoint_path": "checkpoints/mgif-cpk.pth.tar"
    }
}

# ---------------------------
# 2) å…¨å±€ç¼“å­˜ï¼šé¿å…æ¯æ¬¡ç‚¹æŒ‰é’®éƒ½é‡æ–° load æ¨¡å‹
# ---------------------------
_MODEL_CACHE = {
    "model_name": None,
    "generator": None,
    "kp_detector": None,
    "frame_shape": (256, 256),  # (H, W)
    "cpu": False,
}

def _get_video_path(driving_video):
    """å…¼å®¹ä¸åŒ gradio ç‰ˆæœ¬çš„è¿”å›æ ¼å¼ï¼šstr / dict / tuple"""
    if driving_video is None:
        return None
    if isinstance(driving_video, str):
        return driving_video
    if isinstance(driving_video, dict) and "name" in driving_video:
        return driving_video["name"]
    if isinstance(driving_video, (list, tuple)) and len(driving_video) > 0:
        return driving_video[0]
    return str(driving_video)

def _load_yaml_frame_shape(config_path: str):
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f)
        fs = cfg.get("dataset_params", {}).get("frame_shape", [256, 256, 3])
        return (int(fs[0]), int(fs[1]))
    except Exception:
        return (256, 256)

def _load_model_if_needed(model_name: str, cpu: bool = False):
    global _MODEL_CACHE

    if (_MODEL_CACHE["model_name"] == model_name) and (_MODEL_CACHE["generator"] is not None) and (_MODEL_CACHE["cpu"] == cpu):
        return

    # é‡Šæ”¾æ—§æ¨¡å‹ï¼ˆåªä¿ç•™ä¸€ä¸ªï¼Œæ˜¾å­˜æœ€ç¨³ï¼‰
    _MODEL_CACHE["model_name"] = None
    _MODEL_CACHE["generator"] = None
    _MODEL_CACHE["kp_detector"] = None
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

    cfg = MODEL_CONFIG[model_name]
    config_path = cfg["config_path"]
    checkpoint_path = cfg["checkpoint_path"]

    if not os.path.exists(config_path):
        raise gr.Error(f"æ‰¾ä¸åˆ° config: {config_path}")
    if not os.path.exists(checkpoint_path):
        raise gr.Error(f"æ‰¾ä¸åˆ° checkpoint: {checkpoint_path}")

    frame_shape = _load_yaml_frame_shape(config_path)

    generator, kp_detector = load_checkpoints(
        config_path=config_path,
        checkpoint_path=checkpoint_path,
        cpu=cpu
    )

    _MODEL_CACHE.update({
        "model_name": model_name,
        "generator": generator,
        "kp_detector": kp_detector,
        "frame_shape": frame_shape,
        "cpu": cpu,
    })

def _preprocess_source(source_image_np, frame_shape):
    if source_image_np is None:
        raise gr.Error("è¯·æä¾›æºå›¾ç‰‡!")

    img = source_image_np
    if img.dtype != np.float32:
        img = img.astype(np.float32)
    if img.max() > 1.5:
        img = img / 255.0

    h, w = frame_shape
    img = resize(img, (h, w), preserve_range=True)[..., :3]
    return img

def _read_and_preprocess_driving(video_path, frame_shape):
    if video_path is None or not os.path.exists(video_path):
        raise gr.Error("è¯·æä¾›æœ‰æ•ˆçš„é©±åŠ¨è§†é¢‘!")

    reader = imageio.get_reader(video_path)
    meta = reader.get_meta_data()
    fps = meta.get("fps", 25)

    frames = []
    h, w = frame_shape
    try:
        for frame in reader:
            f = frame.astype(np.float32)
            if f.max() > 1.5:
                f = f / 255.0
            f = resize(f, (h, w), preserve_range=True)[..., :3]
            frames.append(f)
    finally:
        reader.close()

    if len(frames) == 0:
        raise gr.Error("é©±åŠ¨è§†é¢‘è¯»å–å¤±è´¥ï¼ˆæ²¡æœ‰å¸§ï¼‰ã€‚")

    return frames, fps

def generate_video(source_image_np, driving_video, model_name, relative=True, adapt_scale=True, use_cpu=False):
    video_path = _get_video_path(driving_video)

    _load_model_if_needed(model_name, cpu=use_cpu)
    generator = _MODEL_CACHE["generator"]
    kp_detector = _MODEL_CACHE["kp_detector"]
    frame_shape = _MODEL_CACHE["frame_shape"]
    cpu = _MODEL_CACHE["cpu"]

    source = _preprocess_source(source_image_np, frame_shape)
    driving, fps = _read_and_preprocess_driving(video_path, frame_shape)

    predictions = make_animation(
        source_image=source,
        driving_video=driving,
        generator=generator,
        kp_detector=kp_detector,
        relative=relative,
        adapt_movement_scale=adapt_scale,
        cpu=cpu
    )

    temp_dir = "gradio_temp"
    os.makedirs(temp_dir, exist_ok=True)
    out_path = os.path.join(temp_dir, f"result_{uuid.uuid4().hex}.mp4")

    writer = imageio.get_writer(out_path, fps=fps, codec="libx264", quality=8)
    try:
        for frame in predictions:
            writer.append_data(img_as_ubyte(frame))
    finally:
        writer.close()

    return out_path


# ---------------------------
# 3) é¢œå€¼æ‹‰æ»¡çš„ UIï¼ˆCSS + Hero + å¡ç‰‡å¸ƒå±€ï¼‰
# ---------------------------
CSS = r"""
/* ===== èƒŒæ™¯ä¸æ•´ä½“ ===== */
.gradio-container {
  max-width: 1200px !important;
  margin: 0 auto !important;
}
body {
  background: radial-gradient(1200px 600px at 10% 0%, rgba(99,102,241,.25), transparent 60%),
              radial-gradient(900px 500px at 100% 30%, rgba(16,185,129,.18), transparent 55%),
              radial-gradient(1000px 600px at 50% 120%, rgba(236,72,153,.16), transparent 60%),
              linear-gradient(180deg, rgba(15,23,42,1) 0%, rgba(2,6,23,1) 100%) !important;
}

/* ===== é¡¶éƒ¨ Hero ===== */
#hero {
  border-radius: 22px;
  padding: 22px 22px 18px 22px;
  background: linear-gradient(135deg, rgba(255,255,255,.10), rgba(255,255,255,.06));
  border: 1px solid rgba(255,255,255,.14);
  box-shadow: 0 18px 60px rgba(0,0,0,.35);
}
#hero h1 {
  margin: 0 !important;
  font-size: 30px !important;
  letter-spacing: .2px;
}
#hero p {
  margin: 8px 0 0 0 !important;
  opacity: .88;
  line-height: 1.5;
}
.badges {
  margin-top: 14px;
  display: flex; gap: 10px; flex-wrap: wrap;
}
.badge {
  padding: 6px 10px;
  border-radius: 999px;
  background: rgba(255,255,255,.10);
  border: 1px solid rgba(255,255,255,.14);
  font-size: 12px;
  opacity: .92;
}

/* ===== å¡ç‰‡é¢æ¿ ===== */
.panel-card {
  border-radius: 18px !important;
  background: linear-gradient(180deg, rgba(255,255,255,.09), rgba(255,255,255,.05)) !important;
  border: 1px solid rgba(255,255,255,.14) !important;
  box-shadow: 0 16px 50px rgba(0,0,0,.30) !important;
  padding: 14px 14px 8px 14px !important;
}
.panel-title {
  font-weight: 700;
  font-size: 15px;
  margin: 0 0 10px 0;
  opacity: .95;
}

/* ===== æŒ‰é’®ç¾åŒ– ===== */
button.primary {
  border-radius: 14px !important;
  font-weight: 700 !important;
  letter-spacing: .2px;
  padding: 12px 14px !important;
  box-shadow: 0 10px 30px rgba(99,102,241,.25) !important;
}
button.secondary {
  border-radius: 14px !important;
  padding: 12px 14px !important;
  background: rgba(255,255,255,.08) !important;
  border: 1px solid rgba(255,255,255,.14) !important;
}

/* ===== çŠ¶æ€æ¡ ===== */
#statusbar {
  border-radius: 14px;
  padding: 10px 12px;
  background: rgba(255,255,255,.08);
  border: 1px solid rgba(255,255,255,.14);
}

/* ===== è®©è§†é¢‘/å›¾ç‰‡æ›´åƒäº§å“ ===== */
video, img {
  border-radius: 14px !important;
}
"""

def pretty_status(kind: str, text: str):
    icon = {"idle":"ğŸŸ£", "run":"ğŸŸ¡", "ok":"ğŸŸ¢", "err":"ğŸ”´"}.get(kind, "â„¹ï¸")
    return f"<div id='statusbar'>{icon} <b>{text}</b></div>"

with gr.Blocks() as demo:
    gr.HTML(
        """
        <div id="hero">
          <h1>ğŸ­ First Order Motion Model Â· WebUI</h1>
          <p>ä¸Šä¼  <b>æºå›¾ç‰‡</b> + <b>é©±åŠ¨è§†é¢‘</b>ï¼Œä¸€é”®ç”Ÿæˆã€Œä¼šåŠ¨çš„ç…§ç‰‡ã€ã€‚ç•Œé¢åšæˆäº§å“çº§ï¼Œæ¨ç†åœ¨è¿›ç¨‹å†…å®Œæˆï¼Œä¸å†åˆ·å‘½ä»¤è¡Œã€‚</p>
          <div class="badges">
            <span class="badge">âš¡ æ¨¡å‹ç¼“å­˜åŠ é€Ÿ</span>
            <span class="badge">ğŸ§  è¿›ç¨‹å†…æ¨ç†</span>
            <span class="badge">ğŸ¬ MP4 è¾“å‡º</span>
            <span class="badge">ğŸ›¡ï¸ å•å¹¶å‘æ›´ç¨³</span>
          </div>
        </div>
        """
    )

    with gr.Row(equal_height=True):
        # å·¦ä¾§ï¼šè¾“å…¥åŒº
        with gr.Column(scale=5):
            with gr.Column(elem_classes=["panel-card"]):
                gr.Markdown("### â‘  æºå›¾ç‰‡", elem_classes=["panel-title"])
                source_image_input = gr.Image(
                    label="Source Image",
                    type="numpy"
                )
                # å¯é€‰ï¼šå¦‚æœä½ æœ‰ assetsï¼Œå°±æ”¾å¼€
                ex1 = os.path.join(os.getcwd(), "assets/source.png")
                ex2 = os.path.join(os.getcwd(), "assets/source_person.png")
                examples = [p for p in [ex1, ex2] if os.path.exists(p)]
                if examples:
                    gr.Examples(
                        examples=examples,
                        inputs=source_image_input,
                        label="ç¤ºä¾‹å›¾ç‰‡ï¼ˆå¯ç›´æ¥ç‚¹å‡»ï¼‰"
                    )
                gr.Markdown(
                    "- å»ºè®®ï¼šæ¸…æ™°æ­£è„¸ / å…‰ç…§å‡åŒ€ / é¿å…é®æŒ¡\n"
                    "- ä½ ä¹Ÿå¯ä»¥ç”¨äººç‰©åŠèº«ç…§åšè¡¨æƒ…è¿ç§»"
                )

            with gr.Column(elem_classes=["panel-card"]):
                gr.Markdown("### â‘¡ é©±åŠ¨è§†é¢‘", elem_classes=["panel-title"])
                driving_video_input = gr.Video(label="Driving Video")
                v1 = os.path.join(os.getcwd(), "assets/driving.mp4")
                v2 = os.path.join(os.getcwd(), "assets/driving_person.mp4")
                v_examples = [p for p in [v1, v2] if os.path.exists(p)]
                if v_examples:
                    gr.Examples(
                        examples=v_examples,
                        inputs=driving_video_input,
                        label="ç¤ºä¾‹è§†é¢‘ï¼ˆå¯ç›´æ¥ç‚¹å‡»ï¼‰"
                    )
                gr.Markdown("- å»ºè®®ï¼š10~30 ç§’ã€é•œå¤´ç¨³å®šã€ä¸»ä½“æ¸…æ™°ï¼ˆæ•ˆæœæ›´å¥½ï¼‰")

            with gr.Column(elem_classes=["panel-card"]):
                gr.Markdown("### â‘¢ é€‰æ‹©æ¨¡å‹ & å‚æ•°", elem_classes=["panel-title"])

                model_selector = gr.Dropdown(
                    choices=list(MODEL_CONFIG.keys()),
                    value="äººè„¸æ¨¡å‹ (vox)",
                    label="é¢„è®­ç»ƒæ¨¡å‹"
                )

                with gr.Row():
                    relative_ck = gr.Checkbox(value=True, label="relativeï¼ˆæ¨èï¼‰")
                    adapt_ck = gr.Checkbox(value=True, label="adapt_scaleï¼ˆæ¨èï¼‰")

                use_cpu_ck = gr.Checkbox(value=False, label="CPU æ¨¡å¼ï¼ˆä»…æ’é”™ / å¾ˆæ…¢ï¼‰")

                with gr.Row():
                    submit_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆ", variant="primary", elem_classes=["primary"])
                    clear_btn = gr.Button("ğŸ”„ æ¸…ç©º", variant="secondary", elem_classes=["secondary"])

        # å³ä¾§ï¼šè¾“å‡ºåŒº
        with gr.Column(scale=7):
            with gr.Column(elem_classes=["panel-card"]):
                gr.Markdown("### â‘£ ç»“æœé¢„è§ˆ", elem_classes=["panel-title"])
                status = gr.HTML(pretty_status("idle", "å¾…å‘½ï¼šè¯·ä¸Šä¼ ç´ æåç‚¹å‡»å¼€å§‹ç”Ÿæˆ"))
                result_video = gr.Video(label="Result", interactive=False)
                gr.Markdown(
                    "å°æç¤ºï¼šå¦‚æœå£å‹/åŠ¨ä½œä¸è‡ªç„¶ï¼Œè¯•è¯•æ¢ä¸€ä¸ªé©±åŠ¨è§†é¢‘ï¼Œæˆ–æ¢ç”¨æ›´åŒ¹é…çš„æ¨¡å‹ï¼ˆæ¯”å¦‚å…¨èº«ç”¨ taichiï¼‰ã€‚"
                )

    # ---------------------------
    # äº‹ä»¶ï¼šç”Ÿæˆ / æ¸…ç©º
    # ---------------------------
    def on_submit(source_image, driving_video, model_name, relative, adapt_scale, use_cpu):
        # UIï¼šå¼€å§‹æ—¶ç¦ç”¨æŒ‰é’® + çŠ¶æ€æç¤º
        yield (
            gr.update(value=None),
            gr.update(value=pretty_status("run", "å¤„ç†ä¸­ï¼šæ¨¡å‹æ¨ç†ä¸­â€¦ï¼ˆè¯·ä¸è¦é‡å¤ç‚¹å‡»ï¼‰")),
            gr.update(interactive=False)
        )

        try:
            out_path = generate_video(source_image, driving_video, model_name, relative, adapt_scale, use_cpu)
            yield (
                gr.update(value=out_path),
                gr.update(value=pretty_status("ok", "å®Œæˆï¼šå·²ç”Ÿæˆè§†é¢‘ âœ…")),
                gr.update(interactive=True)
            )
        except gr.Error as e:
            yield (
                gr.update(value=None),
                gr.update(value=pretty_status("err", f"å¤±è´¥ï¼š{str(e)}")),
                gr.update(interactive=True)
            )
        except Exception as e:
            yield (
                gr.update(value=None),
                gr.update(value=pretty_status("err", f"æœªçŸ¥é”™è¯¯ï¼š{repr(e)}")),
                gr.update(interactive=True)
            )

    def on_clear():
        return None, pretty_status("idle", "å·²æ¸…ç©ºï¼šé‡æ–°ä¸Šä¼ ç´ æå†ç”Ÿæˆ"), gr.update(interactive=True)

    submit_btn.click(
        fn=on_submit,
        inputs=[source_image_input, driving_video_input, model_selector, relative_ck, adapt_ck, use_cpu_ck],
        outputs=[result_video, status, submit_btn]
    )
    clear_btn.click(
        fn=on_clear,
        inputs=[],
        outputs=[result_video, status, submit_btn]
    )


if __name__ == "__main__":
    # å•å¹¶å‘æ›´ç¨³ï¼ˆé¿å…æ˜¾å­˜è¢«å¤šè¯·æ±‚æ‰“çˆ†ï¼‰ï¼›è€ç‰ˆæœ¬ä¸æ”¯æŒå°±å¿½ç•¥
    try:
        demo.queue(concurrency_count=1, max_size=12)
    except Exception:
        pass

    try:
        demo.launch(
            server_name="0.0.0.0",
            theme=gr.themes.Soft(),
            css=CSS
        )
    except Exception:
        demo.launch(
            server_name="0.0.0.0",
            css=CSS
        )
